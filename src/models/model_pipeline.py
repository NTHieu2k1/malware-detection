import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.visualization.explorers import SampleExplorer, BenignExplorer, MalwareExplorer
from src.data.preprocessors import DataPreprocessor
from src.features.selectors import RandomForestSelector
from src.models.train_dev_test_split import TrainDevTestSplit
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import recall_score, fbeta_score, ConfusionMatrixDisplay
from src.utilities.data import merge_dataframes
from src.utilities.file import get_project_root_directory
from pathlib import Path


class RandomForestMalwareDetector:
    def __init__(self):
        self.benign_explorer = BenignExplorer()
        self.malware_explorer = MalwareExplorer()
        self.sample_explorer = SampleExplorer()
        self.preprocessor = DataPreprocessor()
        self.feature_selector = RandomForestSelector()
        self.train_dev_test_split = TrainDevTestSplit()
        self.smote = SMOTE()
        self._scaler = MinMaxScaler()
        self._random_forest_model = RandomForestClassifier(n_estimators=500, n_jobs=-1)
        self.scaled_random_forest_model = Pipeline([('scaler', self._scaler), ('random forest model', self._random_forest_model)])
        self.dev_set_numpy_path = get_project_root_directory() / Path('data/processed/dev_set.npy')
        self.test_set_numpy_path = get_project_root_directory() / Path('data/processed/test_set.npy')

    def _explore_data(self) -> pd.DataFrame:
        self.benign_explorer.get_all_benign_data()
        self.malware_explorer.get_all_malware_data()
        raw_data = merge_dataframes([self.benign_explorer.benign_data, self.malware_explorer.malware_data])
        return raw_data

    def _preprocess_data(self, raw_data: pd.DataFrame) -> pd.DataFrame:
        self.preprocessor.import_data(raw_data)
        self.preprocessor.shuffle_data()
        self.preprocessor.remove_useless_features()
        self.preprocessor.label_encoder()
        self.preprocessor.drop_nan_samples()
        preprocessed_data = self.preprocessor.data
        return preprocessed_data

    def _feature_selection(self, preprocessed_data: pd.DataFrame) -> pd.DataFrame:
        self.feature_selector.import_data(preprocessed_data)
        self.feature_selector.train_selector()
        self.feature_selector.select_features()
        self.feature_selector.transform()
        final_data = self.feature_selector.final_data
        return final_data

    def _train_dev_test_split(self, final_data: pd.DataFrame, dev_size: float, test_size: float):
        self.train_dev_test_split.import_data(final_data)
        return self.train_dev_test_split.train_dev_test_split(test_size, dev_size)

    @staticmethod
    def _save_to_npy(feat_data: np.ndarray, class_data: np.ndarray, file_location):
        with open(file_location, 'wb') as file_save:
            np.save(file_save, feat_data)
            np.save(file_save, class_data)

    def train_model(self, dev_size: float, test_size: float):
        # Explore all raw samples for training, and put them into a dataframe
        raw_data = self._explore_data()
        # Pre-process the data
        preprocessed_data = self._preprocess_data(raw_data)
        # Feature selection
        final_data = self._feature_selection(preprocessed_data)
        # Train-dev-test split
        train_feat, dev_feat, test_feat, train_class, dev_class, test_class = self._train_dev_test_split(final_data,
                                                                                                         dev_size,
                                                                                                         test_size)
        # Save validation (dev) data to a numpy (.npy) file
        self._save_to_npy(dev_feat, dev_class, self.dev_set_numpy_path)
        # Save test data to an another numpy (.npy) file
        self._save_to_npy(test_feat, test_class, self.test_set_numpy_path)
        # Over-sampling the training data (using SMOTE), to make training data balanced
        train_feat_resampled, train_class_resampled = self.smote.fit_resample(train_feat, train_class)
        # Train the Scaled Random Forest model
        self.scaled_random_forest_model.fit(train_feat_resampled, train_class_resampled)

    @staticmethod
    def _load_data_from_npy(file_location):
        with open(file_location, 'rb') as file_load:
            feat_data = np.load(file_load)
            class_data = np.load(file_load)
        return feat_data, class_data

    @staticmethod
    def _display_metrics(evaluation_type: str, ground_truth, predictions):
        print('({0}) Recall:'.format(evaluation_type), end=' ')
        print('%.2f%%' % (recall_score(ground_truth, predictions) * 100))
        print('({0}) F2-score:'.format(evaluation_type), end=' ')
        print('%.2f%%' % (fbeta_score(ground_truth, predictions, beta=2) * 100), end='\n\n')

    @staticmethod
    def _display_confusion_matrix(title: str, ground_truth, predictions, labels=[1, 0], cmap=plt.cm.Blues):
        ConfusionMatrixDisplay.from_predictions(ground_truth, predictions, labels=labels, cmap=cmap)
        plt.title(title)
        plt.show()

    def evaluate_model(self):
        # Load dev set from numpy file
        dev_feat, dev_class = self._load_data_from_npy(self.dev_set_numpy_path)
        # Load test set from numpy file
        test_feat, test_class = self._load_data_from_npy(self.test_set_numpy_path)
        # Use the trained model to predict samples from dev & test sets
        dev_predictions = self.scaled_random_forest_model.predict(dev_feat)
        test_predictions = self.scaled_random_forest_model.predict(test_feat)
        # Display evaluation metrics' results
        self._display_metrics('Test', test_class, test_predictions)
        self._display_metrics('Validation', dev_class, dev_predictions)
        # Display confusion matrix of dev set and test set
        self._display_confusion_matrix('Testing Results', test_class, test_predictions)
        self._display_confusion_matrix('Validation Results', dev_class, dev_predictions)

    @staticmethod
    def _is_missing_values(dataframe: pd.DataFrame) -> bool:
        nan_status_df = dataframe.isna()
        nan_status_array = np.asarray(nan_status_df)[0]
        return any(nan_status_array)

    def _predict_from_dataframe(self, dataframe: pd.DataFrame) -> dict:
        features_data = np.asarray(dataframe)
        probabilities = self.scaled_random_forest_model.predict_proba(features_data)[0]
        positive_probability = probabilities[1]
        negative_probability = probabilities[0]
        prediction_results = {
            'benign': '%.2f%%' % (negative_probability*100),
            'malware': '%.2f%%' % (positive_probability*100)
        }
        return prediction_results

    def predict_a_sample(self, sample_content: bytes):
        # Get all PE headers of the sample
        pe_headers = self.sample_explorer.get_all_pe_information(pe_file_content=sample_content)
        pe_data = pd.DataFrame.from_dict(pe_headers)
        # Feature selection (derived from trained model)
        processed_data = pe_data[self.feature_selector.selected_features]
        # Raise error if there are NaN values in the data
        if self._is_missing_values(processed_data):
            raise ValueError('Missing values encountered in this sample.')
        return self._predict_from_dataframe(processed_data)
