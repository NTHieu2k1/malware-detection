import pandas as pd
import numpy as np
from src.utilities.file import get_project_root_directory
from pathlib import Path

'''Steps:
- Class split into malware & benign separately
- Shuffle two sets
- Split into train, dev & test subsets of each set
- Merge train, dev & test subsets of each class -> 3 sets: train, dev & test sets
'''


class TrainDevTestSplit:
    def __init__(self, dataframe: pd.DataFrame = None):
        self._csv_file = get_project_root_directory() / Path('data/processed/final_malware_dataset.csv')
        if dataframe is None:
            self.data = pd.read_csv(self._csv_file)
        else:
            self.data = dataframe
        self._malware_data = pd.DataFrame()
        self._benign_data = pd.DataFrame()
        self.train_set = pd.DataFrame()
        self.dev_set = pd.DataFrame()
        self.test_set = pd.DataFrame()

    @property
    def malware_data(self):
        return self._malware_data

    @property
    def benign_data(self):
        return self._benign_data

    @malware_data.setter
    def malware_data(self, updated_malware_data):
        self._malware_data = updated_malware_data

    @benign_data.setter
    def benign_data(self, updated_benign_data):
        self._benign_data = updated_benign_data

    def malware_benign_split(self):
        self.benign_data = self.data[self.data['Class'] == 0]
        self.malware_data = self.data[self.data['Class'] == 1]

    @staticmethod
    def shuffle_data(data: pd.DataFrame) -> pd.DataFrame:
        return data.sample(frac=1).reset_index(drop=True)

    @staticmethod
    def set_split(data: pd.DataFrame, test_size: float, dev_size: float):
        # Get the size of train, dev, & test sets
        num_of_samples = len(data)
        num_of_test_samples = int(num_of_samples * test_size)
        num_of_dev_samples = int(num_of_samples * dev_size)
        # Split the data into sets
        num_of_train_samples = num_of_samples - num_of_dev_samples - num_of_test_samples
        train_set = data.iloc[:num_of_train_samples]
        dev_set = data.iloc[num_of_train_samples:num_of_train_samples+num_of_dev_samples]
        test_set = data.iloc[-num_of_test_samples:]
        return train_set, dev_set, test_set

    @staticmethod
    def merge_sets_of_each_class(list_of_sets: list) -> pd.DataFrame:
        merged_set = pd.concat(list_of_sets, axis=0, ignore_index=True)
        return merged_set

    def train_dev_test_split(self, test_size: float, dev_size: float):
        # Split the data into each single class's set
        self.malware_benign_split()
        # Shuffle each set
        self.benign_data = self.shuffle_data(self.benign_data)
        self.malware_data = self.shuffle_data(self.malware_data)
        # Split each set into train, dev & test subsets
        benign_train, benign_dev, benign_test = self.set_split(self.benign_data, test_size, dev_size)
        malware_train, malware_dev, malware_test = self.set_split(self.malware_data, test_size, dev_size)
        # Merge subsets of each class
        self.train_set = self.merge_sets_of_each_class([benign_train, malware_train])
        self.dev_set = self.merge_sets_of_each_class([benign_dev, malware_dev])
        self.test_set = self.merge_sets_of_each_class([benign_test, malware_test])
        # Again, shuffle each newly-merged sets
        self.train_set = self.shuffle_data(self.train_set)
        self.dev_set = self.shuffle_data(self.dev_set)
        self.test_set = self.shuffle_data(self.test_set)
        # Convert to numpy ndarrays
        train_feat = np.asarray(self.train_set.drop(['Class'], axis=1))
        train_class = np.asarray(self.train_set['Class'])
        dev_feat = np.asarray(self.dev_set.drop(['Class'], axis=1))
        dev_class = np.asarray(self.dev_set['Class'])
        test_feat = np.asarray(self.test_set.drop(['Class'], axis=1))
        test_class = np.asarray(self.test_set['Class'])
        return train_feat, dev_feat, test_feat, train_class, dev_class, test_class
