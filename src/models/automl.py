import pandas as pd
import numpy as np
from src.visualization.explorers import SampleExplorer, BenignExplorer, MalwareExplorer
from src.utilities.file import get_project_root_directory, check_file_exist
from src.utilities.data import merge_dataframes, check_imbalanced_dataset
from pathlib import Path
from pycaret.classification import *
from pycaret.utils import check_metric
from sklearn.metrics import fbeta_score


class AutoML:
    def __init__(self):
        self.sample_explorer = SampleExplorer()
        self.benign_explorer = BenignExplorer()
        self.malware_explorer = MalwareExplorer()
        self.model_path = get_project_root_directory() / Path('models')
        self.raw_dataset_path = get_project_root_directory() / Path('data/interim/extracted_malware_dataset.csv')
        self.raw_data = pd.DataFrame()
        self.environment = ()

    def explore_data(self):
        self.benign_explorer.get_all_benign_data()
        self.malware_explorer.get_all_malware_data()
        raw_data = merge_dataframes([self.benign_explorer.benign_data, self.malware_explorer.malware_data])
        self.raw_data = raw_data
        raw_data.to_csv(self.raw_dataset_path)

    def _setup_environment(self):
        # Setup environment
        skipped_features = ['TimeDateStamp']
        all_features = list(self.raw_data.drop(['Class'], axis=1).columns)
        environment = setup(data=self.raw_data, target='Class', train_size=0.85, numeric_features=all_features,
                            ignore_features=skipped_features, normalize=True, normalize_method='minmax', feature_selection=True,
                            feature_selection_threshold=0.225, fix_imbalance=True, session_id=95)
        # Setup metrics
        remove_metric('Kappa')
        remove_metric('MCC')
        fbeta_params = {'beta': 2}
        add_metric('f2', 'F2', fbeta_score, **fbeta_params)
        self.environment = environment

    @staticmethod
    def _build_n_tune_model(model_type: str):
        model = create_model(model_type)
        tuned_model = tune_model(model, optimize='Recall', search_library='optuna', n_iter=30)
        return tuned_model

    @staticmethod
    def _display_evaluation_results(model):
        prediction = predict_model(model)
        recall_score = check_metric(prediction['Class'], prediction['Label'], metric='Recall')
        f2_score = fbeta_score(np.asarray(prediction['Class']), np.asarray(prediction['Label']), beta=2, pos_label='malware')
        print('\nEvaluation Results:')
        print('Recall: %.2f%%' % (recall_score*100))
        print('F2: %.2f%%' % (f2_score*100), end='\n\n')

    def _save_model(self, model, file_name: str):
        model_path = self.model_path / Path(file_name)
        save_model(model, model_path)

    def process_n_train_model(self, model_name: str):
        # Get the dataset, either by extracting software files or reading CSV file
        if not check_file_exist(self.raw_dataset_path):
            self.explore_data()
        else:
            self.raw_data = pd.read_csv(self.raw_dataset_path)
        # Setup environment
        self._setup_environment()
        # Approach derived from notebook: create a combination from a Random Forest model and a Naive Bayes model
        # First, create a Random Forest model
        rf_model = self._build_n_tune_model('rf')
        # Then, create a Naive Bayes model
        nb_model = self._build_n_tune_model('nb')
        # Create a combined model from 2 models
        combined_model = blend_models(estimator_list=[rf_model, nb_model])
        # Display evaluation results
        self._display_evaluation_results(combined_model)
        # Visualize the confusion matrix of combined model
        plot_model(combined_model, plot='confusion_matrix', save=True)
        # Visualize the learning curve
        plot_model(combined_model, plot='learning', save=True)
        # Finalize the model
        combined_final = finalize_model(combined_model)
        # Save the model
        self._save_model(combined_final, model_name)
