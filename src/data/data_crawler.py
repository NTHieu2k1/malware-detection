import os
import asyncio
from pyppeteer import launch, page


def get_project_dir():
    full_dir = os.getcwd()
    if full_dir.find('\\') >= 0:
        full_dir = full_dir.replace('\\', '/')
    inner_dir = 'src/data'
    project_dir = full_dir.replace(inner_dir, '')
    return project_dir


def get_raw_data_dir():
    project_dir = get_project_dir()
    data_subdir = 'data/raw/'
    raw_data_dir = os.path.join(project_dir, data_subdir)
    return raw_data_dir


async def launch_browser():
    return await launch({'headless': False})


async def open_page(browser, url) -> page.Page:
    browser_page = await browser.newPage()
    await browser_page.goto(url)
    return browser_page


async def get_links_and_names(browser) -> dict:
    # Open taimienphi website
    tmp_page = await open_page(browser, url='https://taimienphi.vn')

    # Select "a" tag that contains categories and their urls
    elements = await tmp_page.xpath('//div[@class="bx bxb bgcolr"]/ul/li/a')
    link_elements = dict()

    # Extract urls and categories themselves
    for element in elements:
        link = await tmp_page.evaluate('(element) => element.href', element)
        folder = await tmp_page.evaluate('(element) => element.textContent', element)
        link_elements.update({folder: link})

    await tmp_page.close()
    return link_elements


def preprocessing_link_data(url_data: dict) -> dict:
    """This function is used to pre-process URL-category data crawled in taimienphi website.
    This function consisted of 2 parts: remove some unnecessary categories,
    and replacing whitespaces in names.
    """

    # Define unnecessary categories
    unnecessary_categories = [
        'Mới cập nhật',
        'Top Tải về',
        'Tài liệu',
        'Biểu mẫu',
        'Đề thi',
        'Học ngoại ngữ',
        'Ứng dụng Android',
        'Ứng dụng iOS',
        'Gọi xe',
        'Vận tải, hành khách',
        'Phần mềm mới'
    ]

    for category in list(url_data.keys()):
        # Remove some unnecessary categories
        if category in unnecessary_categories:
            url_data.pop(category)
            continue
        # Other categories: replace whitespaces by underscores
        fixed_category = category.replace(' ', '_')
        # Then apply back to data
        url_data[fixed_category] = url_data.pop(category)

    # Return preprocessed data
    return url_data


async def run_page(browser, url):
    # Open the page
    new_page = await browser.newPage()
    await new_page.goto(url)

    # Keep open for 5 seconds
    await asyncio.sleep(5)

    # Close the page
    await new_page.close()


def make_subdirectories(root_dir, list_subdirs: list) -> list:
    """Make directories for categories and sub-categories,
    as well as creating their paths.
    """
    sub_paths = [os.path.join(root_dir, subdir) for subdir in list_subdirs]
    for sub_path in sub_paths:
        os.mkdir(sub_path)
    return sub_paths


async def run_multi_pages():
    """Just for testing running multiple pages concurrently."""

    # Open browser, and get the url-category data
    browser = await launch_browser()
    link_dict = await get_links_and_names(browser)

    # Preprocessing the url-category data, and get URL and categories data
    link_dict = preprocessing_link_data(link_dict)
    url_list = list(link_dict.values())
    cat_list = list(link_dict.keys())

    # Create folders for corresponding categories, and get their paths
    raw_data_dir = get_raw_data_dir()
    sub_paths = make_subdirectories(raw_data_dir, cat_list)

    # Concurrently open and close all URLs in the URL data
    await asyncio.gather(*[run_page(browser, url) for url in url_list])

    # Close the browser
    await browser.close()


asyncio.run(run_multi_pages())
