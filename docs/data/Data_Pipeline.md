# Data Pipeline

Data pipeline consists of 4 parts:

- Data Cleaning (Validation)
- Data Exploration
- Data Preprocessing
- Feature Selection

## 1. Data Validation:

After getting the data, we realized that several samples in the raw
dataset were not PE samples (which could not be put into processing).
Therefore, data validation phase must be implemented to validate and
keep only PE files for later processing.

Steps to validate the data:

- All samples are put into a PE reader (PE object in
pefile module).
- If a sample is passed by PE reader, the "Magic" header of the file
is checked whether this header's value equals to 267 (because 267 is
equivalent to hexadecimal number 0x10B, and 0x10B indicates PE32 samples).

A sample is PE32, if that sample passes the PE reader and its "Magic"
value equals to 267, and not otherwise. Only PE32 samples are kept
by putting their paths into txt files for further processing.

## 2. Data Exploration:

As the validated samples are all PE32 files, those samples were put in
PE reader again; but in this time, their PE attributes were retrieved.

A typical PE sample has a following structure:

- DOS headers:

![DOS headers](/docs/data/images/dos_header.png)
- Signature header
- File headers:

![File headers](/docs/data/images/image_file_header.png)
- Optional headers:

![Optional headers](/docs/data/images/image_optional_header32.png)

In addition, a PE file also contains a section table and a data directory;
however, these sections were ignored in exploration.

Based on PE structure above, there are some steps to explore the dataset:

- Retrieve PE attributes of each sample via PE reader (except e_res and
e_res2 attributes as these headers do not contain numerical values).
- Labelling each sample based on their location (malware/benign).
- Put all retrieved values with labels of samples into a Pandas dataframe
or CSV file format.

## 3. Data Preprocessing:

After exploring and exporting the dataset to tabular format, data preprocessing
was implemented in order to prepare the data for model training.

Steps for data preprocessing:

- Visualize each feature to measure differences between sample classes.
- Shuffle the dataset to improve model quality.
- Remove unwanted features (such as time-like feature or non-distinguishing
features).
- Convert categorical values (labels) into numerical by encoding.
- Discard samples which contain NaN values.

## 4. Feature Selection:

Although the dataset is clean and ready for training, feature selection
is still necessary to keep only most distinguishing features and reduce
computational cost when training.

In this case, features were selected via feature importances. These
importances were calculated via a Random Forest model. Next, this
model was passed to a Select From Model instance with an importance
threshold to select most important features.

As a result, only features whose importance is higher than the threshold
are kept.
