# Malware Detection - Project Final Report

## 1. Problem motivation:

Malwares are typically software programs that are designed to do malicious
(or unwanted) activities, such as stealing data and identities, encrypting
data, destroying data and systems, without users' permissions. Therefore,
malware attacks may lead to catastrophic impact on computer systems of
individuals, enterprises, and even the government.

In recent years, the number of malware attacks has increased. Moreover,
over 100 millon new malwares were created every year. Therefore, traditional
anti-malware methods (like signature-based) become outdated as those
methods could not keep pace with the rapid development of malwares.
Instead, machine learning based methods have taken place to deal with huge
number of malwares.

## 2. Reseach:

### a. Research plan:

* Search for research papers about "Malware Detection" in various research
paper sources (arXiv, IEEE Xplore, Papers With Code, Research Gate).
* Download, quick-read, and select only newest papers that satisfy metric
conditions (over 90%) for further analyzing.
* Analyze selected papers for extracting authors' ideas, methods, experiment
results, as well as their pros and cons, and suggesting notice when
applying those methods.

### b. Research results:

| # | Paper name | Authors | Year | Methods | Dataset | Results | Pros | Cons | Applying Notice |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 1 | Data Augmentation Based Malware Detection using Convolutional Neural Networks | Ferhat Ozgur Catak, Javed Ahmed, Kevser Sahinbas, Zahid Hussain Khand | 2020 | Train a CNN model using augmented malware images | Dataset include 5762 samples, divided into 7 classes: Worm, Downloader, Spyware, Adware, Exploit, Malware, and Benign | High accurary (>= 90%) on low noise rate, but decrease when noise rate increases | No decompiling required, and models may perform well with malware changes | Model might not perform well | Reshaping is required before converting to images; Augmentation results may vary, depend on augmentation method used |
| 2 | A Novel Malware Detection Mechanism based on Features Extracted from Converted Malware Binary Images | Abhijitt Dhavlle, Sanket Shukla | 2021 | Train ML classifiers (Naive Bayes, Random Forest...) using features extracted from malware images | Dataset includes 9458 malwares of 25 families | Random Forest classifier achived highest results (97%), while Naive Bayes achieved just over 80% | High accuracy though models are not very complex | This research is used for malware classification, not detection | Not suitable for implementation (as this research is not for malware detection) |
| 3 | Mal2GCN: A Robust Malware Detection Approach Using Deep Graph Convolutional Networks With Non-Negative Weights | Omid Kargarnovin, Amir Mahdi Sadeghzadeh, Rasool Jalili | 2021 | Create a Graph Convolutional Network (GCN) combined with non-negative and adversarial training to be robust against adversarial malwares | Dataset includes 58157 PE samples (30975 malwares & 27182 benign samples) | Mal2GCN + adversarial training achieved the highest accuracy (98%), and better than MalConv algorithm | Can be useful for detecting adversarial malwares with high accuracy | Model cannot predict properly with installers, or with malwares that contains dynamic link libraries, Thread Environment Block or encoded strings | Decompiling results may vary on decompilers |
| 4 | On the Design of Supervised Binary Classifiers for Malware Detection using Portable Executable Files | Hrushikesh Shukla, Sonali Patil, Dewang Solanki, Lucky Singh, Mayank Swarnkar, Hiren Kurma Thakkar | 2019 | Training ML classifiers (Decision Tree, Random Forest...) using PE information of samples | Dataset contains malwares and benign samples (5000 samples each) | Random Forest classifier achieved the highest accuracy (97%) while Naive Bayes only achieved around 55% of accuracy | Can detect malwares with high accuracy | Model cannot work well with encrypted softwares | Normalization done in training data should be applied in production data |
| 5 | Malware Detection Based On Opcode Frequency | Abhijit Yewale, Maninder Singh | 2016 | Training ML classifiers using opcode frequency extracted from samples | Dataset contains total of 100 samples for both benign and malware | Random Forest classifier achieved the highest accuracy (97%), while Decision Tree only achieved accuracy of around 80% (the worst) | Models can perform well with high accuracy |  | Assemble code recovered may vary on different disassemblers |
| 6 | Malware Detection based on Cascading XGBoost and Cost Sensitive | Di Wu, Peiqi Guo, Peng Wang | 2020 | Training a model consisting of 3-layer cascading XGBoost components with cost sensitive to deal with imbalanced data | Dataset contains 1650 malwares and 16210 benign samples, all were run in sandbox environment to extract API call sequences | Cascading XGBoost model achieved highest accuracy (just under 100%), and better than other methods | Model can detect malware well, even when training data is skewed |  | API call sequences retrieved might depend on sandbox environment |
| 7 | A learning model to detect maliciousness of portable executable using integrated feature set | Ajit Kumar, K.S. Kuppusamy, G. Aghila | 2017 | Train ML classifiers using feature sets (raw and integrated) extracted from PE information of samples | 2 datasets: Training dataset contains 2488 benign samples and 2722 malwares, and a test (new) dataset contains 129 malwares and 30 benign samples | Random Forest classifier achieved highest accuracy (98%) while Naive Bayes only achieved around 50% accuracy; models trained by integrated set usually better than normal set; test performances were worse than training | Integrated feature set can improve performance of models | Performance may drop when predicting new data, and models only work with PE files |  |
| 8 | Dynamic Malware Analysis with Feature Engineering and Feature Learning | Zhaoqi Zhang, Panpan Qi, Wei Wang | 2020 | Train a deep learning model consisted of a Gate CNN module combined with a bidirectional LSTM module, using API call sequences extracted from files (in sandbox environment) | Dataset contains 27787 malwares and 33400 benign samples | Proposed method achieved highest accuracy (96%), and better than methods from similar papers | Model can perform prediction with high accuracy, even with new data | Long training time, and model may be very complex | Long training time and hardware accelerators (GPU) may be required; and API call sequences retrieved may vary on different environments |
| 9 | Malware detection based on TF-(IDF&ICF) method | Bin Qin, Junpeng Zhang, Hongyu Chen | 2020 | TF-(IDF&ICF) was proposed to extract API calls with multiple dimensions | Dataset contains 1561 malwares and 1051 benign samples | All models achieved just over 97% of F1-score; models trained using features extracted by TF-(IDF&ICF) are better than other extraction methods, as well as lower running time | TF-(IDF&ICF) can improve performance of models, as well as training time | This method only processes data from API call sequences, and usually ignores API arguments | API call sequences retrieved may vary on different environments |
| 10 | Malware Detection Using Machine Learning | Ajay Kumar, Kumar Abhishek, Kunjal Shah, Divy Patel, Yash Jain, Harsh Chheda, Pranav Nerurkar | 2020 | Train ML classifiers using PE information extracted from samples | Brazillian Malware Dataset, which contains total of 100000 samples for both benign and malware | All models achieved high accuracy (> 94%), and Random Forest classifier achieve the highest (99%) | Models can detect malwares with very high accuracy, and performances are better than other methods |  |  |

### c. Reseach summary:

After comparing all methods, the best method chosen was **training ML
classifiers using PE information**, because this method was easy to
apply, and models can achieve high efficiency in detection. In addition,
**Random Forest** algorithm was chosen for training as Random Forest models
usually have better performances than other models.

## 3. Project Implementation:

### a. Dataset:

The dataset used for training and evaluation contains only 6504 benign
files and 1514 malware files. Benign samples were crawled from TaiMienPhi
download website, and malware samples were downloaded from CyRadar's malware
database.

### b. Data Validation, Exploration and Preprocessing:

All samples were scanned and validated to make sure only PE32 files were
kept for further exploration. After validation, the dataset contains only
5311 benign samples and 1514 malware samples. Then all PE32 samples were
put into a PE reader for extracting PE information, then labelled and all
information was put into a single CSV file.

In preprocessing phase, the dataset was shuffled to improve model quality,
then unwanted features (like "TimeDateStamp") were dropped. Next, label
encoding was implemented to convert raw labels ("benign", "malware") to
binary numbers (0, 1), and finally, all rows (samples) that contain NaN
values were dropped.

### c. Feature Selection:

Random Forest algorithm was used for feature selection. After being trained,
importance of each feature was calculated. Based on these importances,
most important features were selected via a Select From Model instance
with a selection threshold.

### d. Fix imbalanced data:

As nearly 78% of samples in the extracted dataset are benign and only
22% of samples are malware, the dataset has become imbalanced. To fix
this issue, an oversampling technique, called SMOTE, was used. SMOTE
stands for Synthetic Minority Over-sampling Technique, and this technique
was used to synthetically oversampling malware-class data to get balanced
with benign-class data.

### e. Training models:

Here is a list of several models that were built and train:

* Random Forest model
* Gradient Boosting model (for boosting)
* Random Forest + Naive Bayes combined model (trained via PyCaret)
* Deep Learning (both shallow and deep neural networks)

Each model were trained, evaluated, and done hyperparameter tuning
(except Gradient Boosting model as no tuning was done for this model).

### f. Model results:

__Note__: As models were trained and tuned multiple times, only best
result of each model will be mentioned in this report.

| Model | Recall | F2-score |
| :---: | :---: | :---: |
| Random Forest | 94.71% | __92.91%__ |
| Gradient Boosting | 93.83% | 87.8% |
| Random Forest + Naive Bayes | __95.93%__ | 77.77% |
| Deep Learning (3-layer NN) | 92.34% | 81.91% |
| Deep Learning (4-layer NN) | 91.06% | 83.12% |
| Deep Learning (6-layer NN) | 92.77% | 85.36% |

## 4. Conclusion:

After training and tuning models, the combined model (Random Forest +
Naive Bayes) was chosen as final model for deployment, because this
model achieved the highest recall. That means the model is able to
detect malware with minimized misses, which is a vital key to protect
computer systems against malware attacks.

## 5. Lessons learned from this project:

* Understanding about the project lifecycle and steps to operate a
typical project.
* Validated sample paths should be copied to a text file for further
processing. This might prevent data loss when validation malfunctioned.
* Understanding tools to operate workflow (e.g. MLflow) and metrics to
evaluate models.